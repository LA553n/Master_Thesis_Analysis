{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To prevent the hassle of installing the package in the wrong environment, \n",
    "# run the following to install phillistine directly into the current environment.\n",
    "# phillistine is a package developed by one of the authors of the Corcoran et al. (2018) paper. \n",
    "# this paper was followed to calculate the IAF scores.\n",
    "import sys\n",
    "print(sys.executable)\n",
    "!{sys.executable} -m pip install --upgrade git+https://gitlab.com/palday/philistine.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne \n",
    "import pandas as pd\n",
    "from philistine.mne import savgol_iaf\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import pyvista as pv\n",
    "import numpy as np\n",
    "import os\n",
    "import math, numbers\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "# Identify the folders where the data is stored\n",
    "buddhist = Path(\"/Users/lucas.assen/Desktop/Master Thesis/Buddhists_preprocessed\")\n",
    "control = Path(\"/Users/lucas.assen/Desktop/Master Thesis/Controls_preprocessed\")\n",
    "\n",
    "# Load the converted FIF files\n",
    "buddhist_fif_files = sorted(glob.glob(str(buddhist / \"*.fif\")))\n",
    "control_fif_files = sorted(glob.glob(str(control / \"*.fif\")))\n",
    "\n",
    "D_0 = {\"Buddhists\": {}, \"Controls\": {}}\n",
    "\n",
    "def load_data_files(file_list, condition):\n",
    "    for file in file_list:\n",
    "        Participant_ID = Path(file).stem\n",
    "        print(f\"Loading {Participant_ID} ({condition})...\")\n",
    "\n",
    "        raw = mne.io.read_raw_fif(file, preload=True)\n",
    "        D_0[condition][Participant_ID] = raw\n",
    "\n",
    "load_data_files(buddhist_fif_files, \"Buddhists\")\n",
    "load_data_files(control_fif_files, \"Controls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The eyes closed marker indicates the start and end of the eyes closed period in the eeg recording; it is used to extract and append the periods\n",
    "# of eyes closed data in each participant.\n",
    "Eyes_closed_marker = 102\n",
    "\n",
    "# The channels refers to the relevant channels for the IAF calculation. These follow the channels used in Corcoran et al. (2018).\n",
    "Channels = ['Pz','P1','P2','POz','PO3','PO4','Oz','O1','O2']\n",
    "\n",
    "# The csv with the bad channels for each participant is loaded to help create a map for each part which shows the channels \n",
    "# that should be excluded from the IAF calculation.\n",
    "BAD_CSV = \"/Users/lucas.assen/Desktop/Master Thesis/bad_channel_summary_2.csv\"\n",
    "bad_df = pd.read_csv(BAD_CSV, sep=\";\", engine=\"python\",\n",
    "                     quoting=csv.QUOTE_NONE).fillna(\"\")\n",
    "bad_df.columns = bad_df.columns.str.strip().str.lower()\n",
    "\n",
    "# Since the participant IDs did not line up in the csv and the fif file, the following defitnition creates \n",
    "# a standardised key for each participant to link up the bad channels with the correct participant.\n",
    "def pid_key(s):\n",
    "    base = re.match(r\"^0*?(\\d+)\", str(s)).group(1)\n",
    "    suff = \"c\" if \"control\" in str(s).lower() else \"\"\n",
    "    return f\"{base}{suff}\"\n",
    "\n",
    "bad_map = {pid_key(r[\"participant_id\"]):\n",
    "           {ch for ch in str(r[\"bad_ch_names\"]).split(\",\") if ch}\n",
    "           for _, r in bad_df.iterrows()}\n",
    "\n",
    "# the following function checks if the value is a real number and finite, which is relevant for the savgol_iaf function.\n",
    "def real_number(x):\n",
    "    return isinstance(x, numbers.Real) and math.isfinite(x)\n",
    "\n",
    "# The following function checks if the channel is in the list of channels used for the IAF calculation.\n",
    "# It returns the index of the channel in the list of channels.\n",
    "# This is used to select the relevant channels from the raw data.\n",
    "def picks_channels(info, bads=set()):\n",
    "    return [info.ch_names.index(ch)\n",
    "            for ch in Channels if ch in info.ch_names and ch not in bads]\n",
    "\n",
    "# The following function extracts the blocks of data between the eyes closed markers.\n",
    "# It finds the markers in the raw data and crops the eyes closed sections to extract and append them.\n",
    "def eyes_closed_blocks(raw, code=Eyes_closed_marker):\n",
    "    events = mne.find_events(raw, 'Status', initial_event=True, shortest_event=0)\n",
    "    sfreq = raw.info['sfreq']; idx = np.where(events[:, 2] == code)[0]\n",
    "    blocks, start = [], None\n",
    "    for ix in idx:\n",
    "        smp = events[ix, 0]\n",
    "        if start is None:\n",
    "            start = smp\n",
    "        else:\n",
    "            blocks.append(raw.copy().crop(start/sfreq, smp/sfreq)); start = None\n",
    "    return blocks\n",
    "\n",
    "# the flattening happens through a log transformation of the psd which is the lineary fitted to yield the background \n",
    "# trend which is then reconstructed by removing the background from the original psd.\n",
    "def flatten_psd(freqs, psd):\n",
    "    mask = (freqs >= 1) & (freqs <= 35)\n",
    "    x, y = np.log10(freqs[mask]), np.log10(psd[mask])\n",
    "    m, c = np.polyfit(x, y, 1)\n",
    "    bg   = 10 ** (m*np.log10(freqs) + c)\n",
    "    return psd / bg\n",
    "\n",
    "# the following function is created to accurately follow the process of calculating the IAF as presented in Corcoran et al. (2018).\n",
    "# In the philistine package, tthe savgol_iaf function lacks the ability to calculate the Q value which is used to wheight each channel in the array for its \n",
    "# contribution to the personalised alpha frequency (PAF) calculation across all channels. According to the paper, the Q value\n",
    "# is calculated by taking the second order derivative to find the inflections points of the PSD curve. These are used to integrate and calculate the area under the curve, \n",
    "# which is divided by the curves width, i.e, the frequency range or difference between the two inflection points, this results in the Q value.\n",
    "def savgol_iaf_channel_Q_weight(raw, picks, fmin=7, fmax=13,\n",
    "                                sg_order=5, sg_window=11):\n",
    "    out, sfreq = {}, raw.info['sfreq']; n_fft = int(2*sfreq)\n",
    "    for p in picks:\n",
    "        ch_raw = raw.copy().pick(picks=[p])\n",
    "\n",
    "        # First the standard savgol_iaf function is applied to get the PAF and CoG values.\n",
    "        paf, cog, (f1, f2) = savgol_iaf(ch_raw, fmin=fmin, fmax=fmax)\n",
    "\n",
    "        # To extract the Q values the proces of the paper is followed whereby the welch PSD is calculated\n",
    "        spec = ch_raw.compute_psd(fmin=fmin, fmax=fmax, n_fft=n_fft, verbose=False)\n",
    "        psd, freqs = spec.get_data()[0], spec.freqs\n",
    "        \n",
    "        # The psd is flattened to remove background noise/to normalise it and the savgol filter is applied using the same parameters as the savgol_iaf function\n",
    "        psd_flat = flatten_psd(freqs, psd)\n",
    "        psd_sg   = savgol_filter(psd_flat, sg_window, sg_order)\n",
    "\n",
    "        # for locating the inflection point the PAF yielded by the savgol_iaf function is used to identify the peak of the PSD curve\n",
    "        # alternatively the highest point of the PSD curve, which will be between 7 and 13 Hz, is used to identify the peak of the PSD curve.\n",
    "        # then the second order derivative is calculated.\n",
    "        idx_peak = (np.argmin(np.abs(freqs - paf))\n",
    "                    if real_number(paf) else psd_sg.argmax())\n",
    "        d2 = np.gradient(np.gradient(psd_sg))\n",
    "\n",
    "        # The to find the inflection points the firest sign changes left and right of the peak are search for.\n",
    "        i_left = idx_peak\n",
    "        while i_left > 1 and np.sign(d2[i_left]) == np.sign(d2[i_left-1]):\n",
    "            i_left -= 1\n",
    "        i1 = freqs[i_left]\n",
    "\n",
    "        i_right = idx_peak\n",
    "        while (i_right < len(d2)-2 and\n",
    "               np.sign(d2[i_right]) == np.sign(d2[i_right+1])):\n",
    "            i_right += 1\n",
    "        i2 = freqs[i_right]\n",
    "\n",
    "        # the q value is then calculate by integrating the area under the curve between the two inflection points, which is then divided by the width of the curve, \n",
    "        # i.e., the difference between the two inflection points.\n",
    "        if real_number(i1) and real_number(i2) and i2 > i1:\n",
    "            band = (freqs >= i1) & (freqs <= i2)\n",
    "            area = np.trapz(psd_sg[band], freqs[band])\n",
    "            Q = area / (i2 - i1)\n",
    "        else:\n",
    "            Q = np.nan\n",
    "\n",
    "        #The outout is the combined output of the savgol_iaf function and the Q value.\n",
    "        out[ch_raw.ch_names[0]] = dict(PAF=paf, CoG=cog, Q=Q,\n",
    "                                       f1=f1, f2=f2, i1=i1, i2=i2)\n",
    "    return out\n",
    "\n",
    "# In the next section all prior function are applied to the whole dictionary of participants and their respective blocks of data.\n",
    "rows = []\n",
    "for group, subs in D_0.items():\n",
    "    for Part_ID, raw in subs.items():\n",
    "        pid = Part_ID.split(\"_\")[0]        \n",
    "        bads = bad_map.get(pid, set())\n",
    "\n",
    "        blocks = eyes_closed_blocks(raw)\n",
    "        if not blocks:\n",
    "            print(f\"{Part_ID}: no Eyes-closed pairs\");  continue\n",
    "\n",
    "        per_block = []\n",
    "        for k, block in enumerate(blocks, 1):\n",
    "            picks = picks_channels(block.info, bads=bads)\n",
    "            if not picks:\n",
    "                print(f\"{Part_ID}: all IAF channels bad in block {k}\");  continue\n",
    "\n",
    "            ch = savgol_iaf_channel_Q_weight(block, picks)\n",
    "\n",
    "            PAF_Q = [(d['PAF'], d['Q']) for d in ch.values()\n",
    "                     if real_number(d['PAF']) and real_number(d['Q'])]\n",
    "            if PAF_Q:\n",
    "                PAF_arr, Q_arr = map(np.array, zip(*PAF_Q))\n",
    "                PAF_m = float((Q_arr/Q_arr.max() * PAF_arr).sum() / (Q_arr/Q_arr.max()).sum())\n",
    "                Q_m   = float(Q_arr.mean())\n",
    "            else:\n",
    "                PAF_m = Q_m = np.nan\n",
    "\n",
    "            CoGs = [d['CoG'] for d in ch.values() if real_number(d['CoG'])]\n",
    "            CoG_m = float(np.mean(CoGs)) if CoGs else np.nan\n",
    "            IAF_m = CoG_m if real_number(CoG_m) else PAF_m\n",
    "\n",
    "            per_block.append((IAF_m, Q_m))\n",
    "            rows.append(dict(group=group, id=Part_ID, block=k,\n",
    "                             PAF_M=PAF_m, CoG_M=CoG_m,\n",
    "                             IAF_M=IAF_m, Q_M=Q_m))\n",
    "\n",
    "        valid = [v for v, _ in per_block if real_number(v)]\n",
    "        if len(valid) > 1:\n",
    "            rows.append(dict(group=group, id=Part_ID,\n",
    "                             block='GA', IAF_GrandAvg=float(np.mean(valid))))\n",
    "        else:\n",
    "            print(f\"{Part_ID}: no valid IAF values â€“ GA skipped\")\n",
    "\n",
    "IAF_df = pd.DataFrame(rows)\n",
    "print(IAF_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the output to a CSV file\n",
    "IAF_df.to_csv('IAF_After_channel_rejection.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the IAF Grand Average values per participant\n",
    "iaf_df = pd.read_csv('/Users/lucas.assen/Desktop/Master Thesis/Data/my_mne_project/mne_env/IAF_After_channel_rejection.csv')\n",
    "\n",
    "bands_df = pd.DataFrame({\n",
    "    'id':           iaf_df['id'],\n",
    "    'delta_low':    0.3,\n",
    "    'delta_high':   0.4 * iaf_df['IAF_GrandAvg'],\n",
    "    'theta_low':    0.4 * iaf_df['IAF_GrandAvg'],\n",
    "    'theta_high':   0.6 * iaf_df['IAF_GrandAvg'],\n",
    "    'alpha_low':    0.6 * iaf_df['IAF_GrandAvg'],\n",
    "    'alpha_high':   1.2 * iaf_df['IAF_GrandAvg'],\n",
    "    'beta_low':     1.2 * iaf_df['IAF_GrandAvg'],\n",
    "    'beta_high':    35.0,\n",
    "})\n",
    "\n",
    "bands = bands_df.dropna(how='any').reset_index(drop=True)\n",
    "bands.to_csv('Individualised_freq_bands_after_chan_reject.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
